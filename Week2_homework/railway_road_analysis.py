import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import streamlit as st
from datetime import datetime
import os
import io
import re
import platform
import matplotlib.font_manager as fm

# è®¾ç½®ä¸­æ–‡å­—ä½“å‡½æ•°
def setup_chinese_font():
    """è®¾ç½®ä¸­æ–‡å­—ä½“ï¼Œè§£å†³ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜"""
    system = platform.system()
    
    # å°è¯•çš„å­—ä½“åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
    if system == "Windows":
        font_candidates = ["SimHei", "Microsoft YaHei", "KaiTi", "FangSong", "Arial Unicode MS"]
    elif system == "Darwin":  # macOS
        font_candidates = ["Heiti TC", "STHeiti", "PingFang SC", "Hiragino Sans GB", "Arial Unicode MS"]
    else:  # Linux
        font_candidates = ["WenQuanYi Micro Hei", "WenQuanYi Zen Hei", "DejaVu Sans", "Arial Unicode MS"]
    
    # æ£€æŸ¥ç³»ç»Ÿä¸­å¯ç”¨çš„å­—ä½“
    available_fonts = []
    for font in font_candidates:
        try:
            # æ£€æŸ¥å­—ä½“æ˜¯å¦å¯ç”¨
            if font in [f.name for f in fm.fontManager.ttflist]:
                available_fonts.append(font)
        except:
            pass
    
    if available_fonts:
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„å­—ä½“
        plt.rcParams["font.family"] = available_fonts
        st.info(f"ä½¿ç”¨å­—ä½“: {available_fonts[0]}")
    else:
        # å¦‚æœæ‰¾ä¸åˆ°ä¸­æ–‡å­—ä½“ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“å¹¶æ˜¾ç¤ºè­¦å‘Š
        plt.rcParams["font.family"] = ["sans-serif"]
        st.warning("æœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œå›¾è¡¨ä¸­çš„ä¸­æ–‡å¯èƒ½æ— æ³•æ­£å¸¸æ˜¾ç¤º")
    
    plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜
    plt.rcParams['xtick.labelsize'] = 8

# åº”ç”¨å­—ä½“è®¾ç½®
setup_chinese_font()

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="é“è·¯å…¬è·¯è¿è´§é‡åˆ†æ",
    page_icon="ğŸš‚",
    layout="wide"
)

# æ ‡é¢˜
st.title("é“è·¯å…¬è·¯è¿è´§é‡å¯¹æ¯”åˆ†æ")

# æ–‡ä»¶å¤„ç† - æ”¯æŒä¸Šä¼ å’Œè·¯å¾„è¾“å…¥
st.sidebar.subheader("æ•°æ®æ–‡ä»¶è®¾ç½®")
file_option = st.sidebar.radio("é€‰æ‹©æ•°æ®æ¥æº", ("ä¸Šä¼ æ–‡ä»¶", "æŒ‡å®šè·¯å¾„"))

excel_path = None
uploaded_file = None

if file_option == "ä¸Šä¼ æ–‡ä»¶":
    uploaded_file = st.sidebar.file_uploader("ä¸Šä¼ Excelæ–‡ä»¶", type=["xls", "xlsx"])
elif file_option == "æŒ‡å®šè·¯å¾„":
    default_path = "C:/Users/Shitianyaa/Python/data/national_data/é“è·¯è¿è¾“.xls"
    excel_path = st.sidebar.text_input("æ–‡ä»¶è·¯å¾„", default_path)

# æ£€æŸ¥æ–‡ä»¶å¯ç”¨æ€§
if (file_option == "æŒ‡å®šè·¯å¾„" and not os.path.exists(excel_path)) or (file_option == "ä¸Šä¼ æ–‡ä»¶" and not uploaded_file):
    st.error("è¯·æä¾›æœ‰æ•ˆçš„Excelæ–‡ä»¶")
    st.stop()

# æ•°æ®åŠ è½½å‡½æ•°
@st.cache_data
def load_data(file_source):
    """åŠ è½½å¹¶è¿”å›æ•°æ®æ¡†"""
    try:
        if isinstance(file_source, str):  # æ–‡ä»¶è·¯å¾„
            return pd.read_excel(file_source)
        else:  # ä¸Šä¼ çš„æ–‡ä»¶
            return pd.read_excel(file_source)
    except Exception as e:
        st.error(f"è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}")
        st.stop()

# æ”¹è¿›çš„æ—¶é—´è§£æå‡½æ•°
def parse_time_column(time_series):
    """æ”¹è¿›çš„æ—¶é—´åˆ—è§£æå‡½æ•°"""
    results = []
    formats = ['%Yå¹´%mæœˆ', '%Y-%m', '%Y/%m', '%Y%m', '%Yå¹´%m', '%Y.%m']
    
    for time_val in time_series:
        if pd.isna(time_val):
            results.append(pd.NaT)
            continue
            
        # å¦‚æœæ˜¯datetimeç±»å‹ç›´æ¥è¿”å›
        if isinstance(time_val, datetime):
            results.append(time_val)
            continue
            
        time_str = str(time_val).strip()
        
        # å°è¯•ç›´æ¥è§£æä¸ºdatetime
        try:
            parsed = pd.to_datetime(time_str)
            results.append(parsed)
            continue
        except:
            pass
        
        # å°è¯•å„ç§æ ¼å¼
        parsed = None
        for fmt in formats:
            try:
                parsed = datetime.strptime(time_str, fmt)
                break
            except:
                continue
        
        # å°è¯•æå–å¹´ä»½å’Œæœˆä»½
        if parsed is None:
            # æŸ¥æ‰¾4ä½æ•°å­—å¹´ä»½
            year_match = re.search(r'(\d{4})', time_str)
            if year_match:
                year = int(year_match.group(1))
                # æŸ¥æ‰¾æœˆä»½
                month_match = re.search(r'[^\d](\d{1,2})[^\d]', time_str.replace(year_match.group(1), ''))
                month = int(month_match.group(1)) if month_match else 1
                try:
                    parsed = datetime(year, month, 1)
                except:
                    parsed = None
        
        results.append(parsed if parsed is not None else pd.NaT)
    
    return pd.Series(results, index=time_series.index)

# æ•°æ®é¢„å¤„ç†å‡½æ•°
def preprocess_data(df):
    """é¢„å¤„ç†æ•°æ®ï¼Œä¸»è¦å¤„ç†æ—¶é—´åˆ—"""
    # è‡ªåŠ¨è¯†åˆ«æ—¶é—´åˆ—
    time_cols = [col for col in df.columns if any(keyword in str(col) for keyword in ['æ—¶é—´', 'æ—¥æœŸ', 'å¹´æœˆ', 'æœˆä»½', 'æ—¶æœŸ'])]
    
    if not time_cols:
        st.warning("æœªå‘ç°æ—¶é—´ç›¸å…³åˆ—ï¼Œä½¿ç”¨ç´¢å¼•ä½œä¸ºæ—¶é—´å‚è€ƒ")
        df['æ—¶é—´'] = pd.date_range(start='2000-01-01', periods=len(df), freq='M')
        return df
    
    time_col = time_cols[0]
    st.info(f"ä½¿ç”¨ '{time_col}' ä½œä¸ºæ—¶é—´åˆ—")
    
    # åº”ç”¨æ—¶é—´è½¬æ¢
    original_len = len(df)
    df['æ—¶é—´'] = parse_time_column(df[time_col])
    
    # æ¸…ç†æ•°æ®
    cleaned_df = df.dropna(subset=['æ—¶é—´']).copy()
    cleaned_df = cleaned_df.sort_values(by='æ—¶é—´').reset_index(drop=True)
    
    # æ£€æŸ¥æ•°æ®æŸå¤±
    if len(cleaned_df) < original_len:
        st.warning(f"æ—¶é—´æ ¼å¼è½¬æ¢åæ•°æ®æŸå¤±: {original_len - len(cleaned_df)} è¡Œ")
    
    return cleaned_df

# æ”¹è¿›çš„åˆ—ååŒ¹é…å‡½æ•°
def find_matching_columns(df, keywords, exclude_keywords=None):
    """æ ¹æ®å…³é”®è¯åˆ—è¡¨æŸ¥æ‰¾åŒ¹é…çš„åˆ—å"""
    if exclude_keywords is None:
        exclude_keywords = []
    
    best_match = None
    best_score = 0
    
    for col in df.columns:
        col_str = str(col).lower()
        
        # æ’é™¤åŒ…å«æ’é™¤å…³é”®è¯çš„åˆ—
        if any(exclude in col_str for exclude in exclude_keywords):
            continue
            
        # è®¡ç®—åŒ¹é…åˆ†æ•°
        score = sum(1 for keyword in keywords if keyword.lower() in col_str)
        
        # å¦‚æœæ‰€æœ‰å…³é”®è¯éƒ½åŒ¹é…ï¼Œå¹¶ä¸”åˆ†æ•°æ›´é«˜ï¼Œåˆ™æ›´æ–°æœ€ä½³åŒ¹é…
        if score == len(keywords) and score > best_score:
            best_match = col
            best_score = score
        # å¦‚æœéƒ¨åˆ†åŒ¹é…ï¼Œä½†åˆ†æ•°æ›´é«˜ï¼Œä¹Ÿè€ƒè™‘
        elif score > best_score:
            best_match = col
            best_score = score
    
    return best_match

# ä¸»é€»è¾‘
try:
    # åŠ è½½æ•°æ®
    df = load_data(excel_path if file_option == "æŒ‡å®šè·¯å¾„" else uploaded_file)
    
    # æ˜¾ç¤ºåŸå§‹æ•°æ®ä¿¡æ¯
    st.subheader("åŸå§‹æ•°æ®ä¿¡æ¯")
    st.write(f"æ•°æ®å½¢çŠ¶: {df.shape} (è¡Œ: {df.shape[0]}, åˆ—: {df.shape[1]})")
    
    # æ˜¾ç¤ºåˆ—ä¿¡æ¯
    with st.expander("åŸå§‹åˆ—ååŠæ•°æ®ç±»å‹", expanded=False):
        col_info = pd.DataFrame({
            'åˆ—ç´¢å¼•': range(len(df.columns)),
            'åˆ—å': df.columns,
            'æ•°æ®ç±»å‹': df.dtypes.astype(str)
        })
        st.dataframe(col_info)
    
    # é¢„å¤„ç†æ•°æ®
    df_processed = preprocess_data(df)
    
    # æ˜¾ç¤ºå¤„ç†åçš„æ•°æ®é¢„è§ˆ
    with st.expander("å¤„ç†åçš„æ•°æ®é¢„è§ˆ", expanded=False):
        st.dataframe(df_processed.head(10))
        st.write(f"å¤„ç†åæ•°æ®å½¢çŠ¶: {df_processed.shape}")
    
    # æ™ºèƒ½è¯†åˆ«ç›¸å…³åˆ— - æ”¹è¿›çš„åŒ¹é…é€»è¾‘
    railway_columns = {
        'å½“æœŸå€¼': find_matching_columns(df_processed, ['é“è·¯', 'è´§è¿é‡', 'å½“æœŸ'], exclude_keywords=['å¢é•¿', 'åŒæ¯”', 'ç´¯è®¡']),
        'ç´¯è®¡å€¼': find_matching_columns(df_processed, ['é“è·¯', 'è´§è¿é‡', 'ç´¯è®¡'], exclude_keywords=['å¢é•¿', 'åŒæ¯”']),
        'åŒæ¯”å¢é•¿': find_matching_columns(df_processed, ['é“è·¯', 'è´§è¿é‡', 'åŒæ¯”', 'å¢é•¿']),
        'ç´¯è®¡å¢é•¿': find_matching_columns(df_processed, ['é“è·¯', 'è´§è¿é‡', 'ç´¯è®¡', 'å¢é•¿'])
    }
    
    road_columns = {
        'å½“æœŸå€¼': find_matching_columns(df_processed, ['å…¬è·¯', 'è´§è¿é‡', 'å½“æœŸ'], exclude_keywords=['å¢é•¿', 'åŒæ¯”', 'ç´¯è®¡']),
        'ç´¯è®¡å€¼': find_matching_columns(df_processed, ['å…¬è·¯', 'è´§è¿é‡', 'ç´¯è®¡'], exclude_keywords=['å¢é•¿', 'åŒæ¯”']),
        'åŒæ¯”å¢é•¿': find_matching_columns(df_processed, ['å…¬è·¯', 'è´§è¿é‡', 'åŒæ¯”', 'å¢é•¿']),
        'ç´¯è®¡å¢é•¿': find_matching_columns(df_processed, ['å…¬è·¯', 'è´§è¿é‡', 'ç´¯è®¡', 'å¢é•¿'])
    }
    
    # æ£€æŸ¥å¹¶è¿‡æ»¤ä¸å­˜åœ¨çš„åˆ— - ä¿®å¤è¿™é‡Œçš„è¯­æ³•é”™è¯¯
    valid_rail = {k: v for k, v in railway_columns.items() if v is not None}
    valid_road = {k: v for k, v in road_columns.items() if v is not None}  # ä¿®å¤è¿™é‡Œï¼šä½¿ç”¨å†’å·è€Œä¸æ˜¯é€—å·
    
    # æ˜¾ç¤ºæ‰¾åˆ°çš„åˆ—ä¿¡æ¯
    st.subheader("è¯†åˆ«åˆ°çš„æ•°æ®åˆ—")
    col1, col2 = st.columns(2)
    with col1:
        st.write("é“è·¯ç›¸å…³åˆ—:")
        for k, v in valid_rail.items():
            st.write(f"  {k}: {v}")
    with col2:
        st.write("å…¬è·¯ç›¸å…³åˆ—:")
        for k, v in valid_road.items():
            st.write(f"  {k}: {v}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„åˆ—è¿›è¡Œåˆ†æ
    if not valid_rail or not valid_road:
        st.error("æœªæ‰¾åˆ°è¶³å¤Ÿçš„é“è·¯æˆ–å…¬è·¯æ•°æ®åˆ—ï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶")
        st.stop()
    
    # ç”¨æˆ·é€‰æ‹©æ•°æ®ç±»å‹
    st.subheader("æ•°æ®åˆ†æé…ç½®")
    available_types = list(set(valid_rail.keys()) & set(valid_road.keys()))
    if not available_types:
        st.error("æ²¡æœ‰å¯å¯¹æ¯”çš„æ•°æ®åˆ†æç±»å‹")
        st.stop()
    
    data_type = st.radio("é€‰æ‹©æ•°æ®ç±»å‹", available_types)
    
    # è·å–å¯¹åº”çš„åˆ—å
    railway_col = valid_rail[data_type]
    road_col = valid_road[data_type]
    
    # ç¡®ä¿ä½¿ç”¨è¿è´§é‡æ•°æ®è€Œä¸æ˜¯å¢é•¿ç‡æ•°æ®è¿›è¡Œå æ¯”å’Œç›¸å…³æ€§åˆ†æ
    volume_rail_col = valid_rail.get('å½“æœŸå€¼') or valid_rail.get('ç´¯è®¡å€¼')
    volume_road_col = valid_road.get('å½“æœŸå€¼') or valid_road.get('ç´¯è®¡å€¼')
    
    # éªŒè¯æ•°æ®åˆ—å­˜åœ¨
    if not volume_rail_col or not volume_road_col:
        st.error("æ— æ³•æ‰¾åˆ°è¿è´§é‡æ•°æ®åˆ—è¿›è¡Œå æ¯”å’Œç›¸å…³æ€§åˆ†æ")
        st.stop()
    
    # ç¡®ä¿æ•°æ®æ˜¯æ•°å€¼ç±»å‹
    for col in [railway_col, road_col, volume_rail_col, volume_road_col]:
        df_processed[col] = pd.to_numeric(df_processed[col], errors='coerce')
    
    # ç§»é™¤åŒ…å«NaNçš„è¡Œ
    analysis_df = df_processed.dropna(subset=[volume_rail_col, volume_road_col, 'æ—¶é—´']).copy()
    
    if len(analysis_df) == 0:
        st.error("è¿è´§é‡æ•°æ®æ— æ•ˆï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
        st.stop()
    
    # å¯è§†åŒ–éƒ¨åˆ† - è¿è´§é‡å¯¹æ¯”
    st.subheader("é“è·¯å…¬è·¯è¿è´§é‡å¯¹æ¯”")
    fig, ax = plt.subplots(figsize=(12, 6))
    width = 0.35
    x = np.arange(len(analysis_df['æ—¶é—´']))
    
    # ç»˜åˆ¶è¿è´§é‡
    ax.bar(x - width/2, analysis_df[railway_col], width, label='é“è·¯è¿è´§é‡', alpha=0.7, color='blue')
    ax.bar(x + width/2, analysis_df[road_col], width, label='å…¬è·¯è¿è´§é‡', alpha=0.7, color='orange')
    
    # è®¾ç½®å›¾è¡¨å±æ€§
    ax.set_xlabel('æ—¶é—´')
    ax.set_ylabel('è¿è´§é‡(ä¸‡å¨)')
    ax.set_title(f'é“è·¯å…¬è·¯{data_type}å¯¹æ¯”')
    ax.legend(loc='upper left')
    
    # åŠ¨æ€è°ƒæ•´xè½´åˆ»åº¦
    step = max(1, len(analysis_df) // 15)
    ax.set_xticks(x[::step])
    ax.set_xticklabels([t.strftime('%Y-%m') for t in analysis_df['æ—¶é—´'][::step]], rotation=30, ha='right')
    
    plt.tight_layout()
    st.pyplot(fig)
    
    # å¢é•¿ç‡è¶‹åŠ¿å›¾ï¼ˆå¦‚æœå­˜åœ¨å¢é•¿ç‡åˆ—ï¼‰
    railway_growth_col = valid_rail.get('åŒæ¯”å¢é•¿') or valid_rail.get('ç´¯è®¡å¢é•¿')
    road_growth_col = valid_road.get('åŒæ¯”å¢é•¿') or valid_road.get('ç´¯è®¡å¢é•¿')
    
    if railway_growth_col or road_growth_col:
        st.subheader("å¢é•¿ç‡å˜åŒ–è¶‹åŠ¿")
        fig2, ax2 = plt.subplots(figsize=(12, 6))
        
        if railway_growth_col:
            # ç¡®ä¿å¢é•¿ç‡åˆ—æ˜¯æ•°å€¼ç±»å‹
            analysis_df[railway_growth_col] = pd.to_numeric(analysis_df[railway_growth_col], errors='coerce')
            ax2.plot(analysis_df['æ—¶é—´'], analysis_df[railway_growth_col], marker='o', label='é“è·¯å¢é•¿ç‡(%)', color='blue')
        
        if road_growth_col:
            # ç¡®ä¿å¢é•¿ç‡åˆ—æ˜¯æ•°å€¼ç±»å‹
            analysis_df[road_growth_col] = pd.to_numeric(analysis_df[road_growth_col], errors='coerce')
            ax2.plot(analysis_df['æ—¶é—´'], analysis_df[road_growth_col], marker='s', label='å…¬è·¯å¢é•¿ç‡(%)', color='orange')
        
        ax2.axhline(y=0, color='r', linestyle='-', alpha=0.3)
        ax2.set_xlabel('æ—¶é—´')
        ax2.set_ylabel('å¢é•¿ç‡(%)')
        ax2.set_title(f'é“è·¯å…¬è·¯è¿è´§é‡{data_type}å¢é•¿ç‡å˜åŒ–è¶‹åŠ¿')
        ax2.legend()
        
        plt.gcf().autofmt_xdate(rotation=30)
        plt.tight_layout()
        st.pyplot(fig2)
    
    # ä¿®æ­£çš„å †å å›¾åˆ†æ - ä½¿ç”¨è¿è´§é‡æ•°æ®
    st.subheader("é“è·¯å…¬è·¯è¿è´§é‡å æ¯”åˆ†æ")
    fig3, ax3 = plt.subplots(figsize=(12, 6))
    
    # ä½¿ç”¨è¿è´§é‡æ•°æ®è€Œä¸æ˜¯å¢é•¿ç‡æ•°æ®
    total = analysis_df[volume_rail_col] + analysis_df[volume_road_col]
    
    # å¤„ç†é™¤é›¶é—®é¢˜
    valid_mask = total > 0
    if valid_mask.sum() == 0:
        st.warning("è¿è´§é‡æ•°æ®å…¨ä¸ºé›¶ï¼Œæ— æ³•è®¡ç®—å æ¯”")
    else:
        railway_percentage = np.where(valid_mask, (analysis_df[volume_rail_col] / total) * 100, 0)
        road_percentage = np.where(valid_mask, (analysis_df[volume_road_col] / total) * 100, 0)
        
        # åªä½¿ç”¨æœ‰æ•ˆæ•°æ®
        valid_times = analysis_df['æ—¶é—´'][valid_mask]
        valid_rail_pct = railway_percentage[valid_mask]
        valid_road_pct = road_percentage[valid_mask]
        
        if len(valid_times) > 0:
            ax3.stackplot(valid_times, valid_rail_pct, valid_road_pct, 
                         labels=['é“è·¯å æ¯”', 'å…¬è·¯å æ¯”'], colors=['blue', 'orange'], alpha=0.8)
            ax3.set_xlabel('æ—¶é—´')
            ax3.set_ylabel('å æ¯”(%)')
            ax3.set_title('é“è·¯å…¬è·¯è¿è´§é‡å æ¯”å˜åŒ–è¶‹åŠ¿')
            ax3.legend(loc='upper left')
            
            plt.gcf().autofmt_xdate(rotation=30)
            plt.tight_layout()
            st.pyplot(fig3)
        else:
            st.warning("æ²¡æœ‰æœ‰æ•ˆçš„è¿è´§é‡æ•°æ®è¿›è¡Œå æ¯”åˆ†æ")
    
    # ä¿®æ­£çš„ç›¸å…³æ€§åˆ†æ - ä½¿ç”¨è¿è´§é‡æ•°æ®
    st.subheader("ç›¸å…³æ€§åˆ†æ")
    
    # ä½¿ç”¨è¿è´§é‡æ•°æ®è¿›è¡Œç›¸å…³æ€§åˆ†æ
    corr_data = analysis_df[[volume_rail_col, volume_road_col]].dropna()
    
    if len(corr_data) < 2:
        st.warning("æ•°æ®é‡ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œç›¸å…³æ€§åˆ†æ")
    else:
        # è®¡ç®—ç›¸å…³ç³»æ•°
        correlation = np.corrcoef(corr_data[volume_rail_col], corr_data[volume_road_col])[0, 1]
        
        # åˆ¤æ–­ç›¸å…³æ€§å¼ºåº¦
        if abs(correlation) > 0.7:
            strength = "å¼º"
        elif abs(correlation) > 0.3:
            strength = "ä¸­ç­‰"
        else:
            strength = "å¼±"
        
        relation = "æ­£" if correlation > 0 else "è´Ÿ"
        
        st.write(f"é“è·¯ä¸å…¬è·¯è¿è´§é‡ç›¸å…³ç³»æ•°: {correlation:.4f}")
        st.write(f"ç›¸å…³æ€§: {strength}{relation}ç›¸å…³")
        
        fig4, ax4 = plt.subplots(figsize=(10, 6))
        ax4.scatter(corr_data[volume_rail_col], corr_data[volume_road_col], alpha=0.7, color='purple')
        ax4.set_xlabel(f'é“è·¯è¿è´§é‡(ä¸‡å¨)')
        ax4.set_ylabel(f'å…¬è·¯è¿è´§é‡(ä¸‡å¨)')
        ax4.set_title('é“è·¯ä¸å…¬è·¯è¿è´§é‡æ•£ç‚¹å›¾')
        
        # æ·»åŠ è¶‹åŠ¿çº¿ï¼ˆä»…å½“æœ‰è¶³å¤Ÿæ•°æ®ç‚¹ä¸”ç›¸å…³æ€§è¾ƒå¼ºæ—¶ï¼‰
        if len(corr_data) > 2 and abs(correlation) > 0.3:
            z = np.polyfit(corr_data[volume_rail_col], corr_data[volume_road_col], 1)
            p = np.poly1d(z)
            ax4.plot(corr_data[volume_rail_col], p(corr_data[volume_rail_col]), "--", color='red', 
                    label=f'è¶‹åŠ¿çº¿ (r={correlation:.3f})')
            ax4.legend()
        
        plt.tight_layout()
        st.pyplot(fig4)
    
    # æ•°æ®å¯¼å‡ºåŠŸèƒ½
    st.subheader("æ•°æ®å¯¼å‡º")
    export_columns = ['æ—¶é—´', railway_col, road_col]
    
    if railway_growth_col:
        export_columns.append(railway_growth_col)
    if road_growth_col:
        export_columns.append(road_growth_col)
    
    export_df = analysis_df[export_columns].copy()
    # æ ¼å¼åŒ–æ—¶é—´åˆ—
    export_df['æ—¶é—´'] = export_df['æ—¶é—´'].dt.strftime('%Y-%m')
    csv = export_df.to_csv(index=False).encode('utf-8')
    st.download_button(
        label="ä¸‹è½½åˆ†ææ•°æ® (CSV)",
        data=csv,
        file_name=f"é“è·¯å…¬è·¯è¿è´§é‡åˆ†æ_{data_type}_{datetime.now().strftime('%Y%m%d')}.csv",
        mime="text/csv",
    )
    
    # ç»Ÿè®¡æ‘˜è¦
    st.subheader("ç»Ÿè®¡æ‘˜è¦")
    
    # å‡†å¤‡ç»Ÿè®¡æ•°æ®
    stats_data = {'æŒ‡æ ‡': ['å¹³å‡å€¼', 'æœ€å¤§å€¼', 'æœ€å°å€¼', 'æ ‡å‡†å·®', 'æ•°æ®é‡']}
    
    # é“è·¯è¿è´§é‡ç»Ÿè®¡
    rail_stats = [
        analysis_df[railway_col].mean(),
        analysis_df[railway_col].max(),
        analysis_df[railway_col].min(),
        analysis_df[railway_col].std(),
        analysis_df[railway_col].count()
    ]
    stats_data['é“è·¯è¿è´§é‡'] = rail_stats
    
    # å…¬è·¯è¿è´§é‡ç»Ÿè®¡
    road_stats = [
        analysis_df[road_col].mean(),
        analysis_df[road_col].max(),
        analysis_df[road_col].min(),
        analysis_df[road_col].std(),
        analysis_df[road_col].count()
    ]
    stats_data['å…¬è·¯è¿è´§é‡'] = road_stats
    
    # å¢é•¿ç‡ç»Ÿè®¡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if railway_growth_col:
        rail_growth_stats = [
            analysis_df[railway_growth_col].mean(),
            analysis_df[railway_growth_col].max(),
            analysis_df[railway_growth_col].min(),
            analysis_df[railway_growth_col].std(),
            analysis_df[railway_growth_col].count()
        ]
        stats_data['é“è·¯å¢é•¿ç‡(%)'] = rail_growth_stats
    
    if road_growth_col:
        road_growth_stats = [
            analysis_df[road_growth_col].mean(),
            analysis_df[road_growth_col].max(),
            analysis_df[road_growth_col].min(),
            analysis_df[road_growth_col].std(),
            analysis_df[road_growth_col].count()
        ]
        stats_data['å…¬è·¯å¢é•¿ç‡(%)'] = road_growth_stats
    
    # åˆ›å»ºç»Ÿè®¡è¡¨æ ¼
    stats_df = pd.DataFrame(stats_data)
    
    # æ ¼å¼åŒ–æ•°å€¼
    for col in stats_df.columns[1:]:
        stats_df[col] = stats_df[col].apply(
            lambda x: f"{x:.2f}" if isinstance(x, (int, float)) and not np.isnan(x) else "N/A"
        )
    
    st.dataframe(stats_df)
    
except Exception as e:
    st.error(f"å¤„ç†æ•°æ®æ—¶å‡ºé”™: {str(e)}")
    st.exception(e)